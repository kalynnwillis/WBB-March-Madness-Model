---
title: "Women's Basketball March Madness: Bradley-Terry Model Analysis"
subtitle: "Analyzing Mid-Tier Seed (8-12) Advancement Probabilities"
author: "Kalynn Willis, Jasmine, Ellie"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    theme: flatly
    code_folding: hide
    fig_width: 10
    fig_height: 6
  pdf_document:
    toc: true
    toc_depth: 3
    fig_width: 10
    fig_height: 6
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    message = FALSE,
    warning = FALSE,
    fig.align = "center"
)

library(tidyverse)
library(here)
library(knitr)
library(kableExtra)

# Helper function for safe file reading
read_if_exists <- function(path) {
    if (file.exists(path)) {
        if (grepl("\\.rds$", path)) {
            return(readRDS(path))
        } else if (grepl("\\.csv$", path)) {
            return(read_csv(path, show_col_types = FALSE))
        }
    }
    return(NULL)
}
```

# Executive Summary {.unnumbered}

Every March, the NCAA Women's Basketball Tournament captures national attention with underdog stories. But in 2023 and 2024, something unusual happened: not a single mid-tier team—those seeded 8 through 12—made it to the Sweet Sixteen. Were these back-to-back "chalk" tournaments (where favorites win) a statistical fluke, or should we expect this regularly?

This study examines middle-seeded teams in March Madness to answer: **How often do 8-12 seeds make deep runs, and which ones should we watch most closely?**

We analyzed over 5,000 regular season games to create strength ratings for all tournament teams—accounting for who you played and how you performed against them, not just wins and losses. We then simulated the entire tournament 5,000 times to see what typically happens to teams seeded 8-12.

## Main Findings

In a typical tournament, expect about two teams seeded 8-12 to reach the Sweet Sixteen. Sometimes zero, sometimes four, but two is average. The 2023-2024 drought has about an 18% chance of happening—like flipping heads three times in a row. Unusual, but not shocking. It'll naturally occur about once every five or six years.

When a mid-tier seed breaks through to the Sweet Sixteen, what happens next? About one in five reach the Final Four, and only one in twenty-seven win the championship. Making the Sweet Sixteen is the hardest part; once there, they're competitive but still underdogs against top seeds.

Perhaps most importantly, seed numbers don't tell the whole story. Stanford (11-seed) has a 62.5% chance of reaching the Sweet Sixteen—better than many higher-seeded teams. Some 12-seeds have less than 20% chance. The difference? Stanford had an exceptionally strong regular season. Their seed says "underdog," but their performance says "contender."

```{r load-results, echo=FALSE}
# Load key results
key_results <- read_if_exists(here("results", "tables", "key_results.rds"))
sweet16_probs <- read_if_exists(here("results", "tables", "sweet16_mid_tier_probabilities.csv"))
```

**Key Numbers:**

- **Expected 8-12 seeds in Sweet 16:** `r if(!is.null(key_results)) sprintf("%.2f", key_results$expected_in_sweet16) else "~1.7"` teams
- **Conditional probability of reaching Finals (given Sweet 16):** `r if(!is.null(key_results)) sprintf("%.1f%%", key_results$overall_conditional$prob_finals_given_s16 * 100) else "~8.8%"`
- **Conditional probability of winning championship (given Sweet 16):** `r if(!is.null(key_results)) sprintf("%.1f%%", key_results$overall_conditional$prob_champion_given_s16 * 100) else "~3.7%"`
- **Highest Sweet 16 probability:** `r if(!is.null(sweet16_probs)) paste0(sweet16_probs$winner_name[1], " (", sweet16_probs$seed[1], "-seed) at ", sprintf("%.1f%%", sweet16_probs$percentage[1])) else "Stanford (11-seed) at 62.5%"`

## What This Means

**For bracket predictions:** Be conservative with upset picks. Expecting five or six mid-tier seeds in the Sweet Sixteen is overly optimistic. Pick one or two strong candidates like Stanford rather than hoping for multiple Cinderella stories.

**For coaches and teams:** Regular season success translates directly to tournament opportunity. Strong performance against quality opponents measurably improves your chances, even with a middling seed. The difference between the strongest and weakest 8-12 seeds is substantial.

**For fans and media:** When a 10-seed reaches the Elite Eight, celebrate appropriately. It's genuinely rare, happening in only 5-10% of tournaments.

## The Bottom Line

The past two tournaments showed what happens when favorites dominate, but history suggests that won't last. Mid-tier seeds will break through again. Understanding individual team strength, beyond just seed numbers, helps identify those breakthrough candidates. Basketball remains beautifully unpredictable, but patterns emerge. Expect about two mid-tier seeds to reach the Sweet Sixteen in most years, with perhaps one making a deeper run.

---

# 1. Introduction

## 1.1 Motivation and Problem Statement

The NCAA Division I Women's Basketball Tournament, colloquially known as "March Madness," is an annual single-elimination tournament featuring 64 teams seeded 1-16 across four regional brackets. Understanding tournament dynamics—particularly the advancement patterns of mid-tier seeds—has practical value for:

- **Sports Analytics:** Quantifying competitive balance and upset potential
- **Bracket Prediction:** Informed probabilistic forecasting
- **Team Evaluation:** Identifying over/under-seeded teams
- **Media and Fans:** Setting appropriate expectations for underdog stories

## 1.2 Why Focus on 8-12 Seeds?

Seeds 8-12 occupy a strategic middle ground in tournament analysis:

1. **Not Automatic Exits:** Unlike 13-16 seeds (which rarely win first-round games), 8-12 seeds have realistic chances to win at least one game
2. **Not Overwhelming Favorites:** Unlike 1-4 seeds (which typically dominate early rounds), 8-12 seeds face genuine competitive challenges
3. **Upset Potential:** These teams represent the "Cinderella" sweet spot—capable of deep runs but facing long odds
4. **Practical Relevance:** Understanding this tier helps calibrate reasonable expectations vs. hype

## 1.3 Research Questions

This analysis addresses two primary research questions:

**Research Question 1:** How many of the 8-12 seeds should we expect to advance past the second round (to the Sweet 16)?

**Research Question 2:** Given that a team seeded 8-12 advanced past the second round, what is the probability they reach the finals or win the championship?

Additionally, we extend the analysis to:

- Calculate **individual team probabilities** for each specific 8-12 seed
- Contextualize the 2023-2024 historical outcome (zero 8-12 seeds in Sweet 16)
- Validate analytical predictions with Monte Carlo simulation

## 1.4 Historical Context

In both the 2023 and 2024 NCAA Women's Basketball Tournaments, **no teams seeded 8-12 reached the Sweet 16**. This unprecedented back-to-back occurrence motivates our analysis: Is this outcome statistically unusual, or should we expect such scenarios regularly?

---

# 2. Methodology

## 2.1 Bradley-Terry Model Framework

### Model Specification

The Bradley-Terry model is a probabilistic framework for modeling pairwise comparisons. For teams $i$ and $j$ with latent strength parameters $\lambda_i$ and $\lambda_j$, the probability that team $i$ defeats team $j$ is:

$$
P(\text{team } i \text{ beats team } j) = \frac{e^{\lambda_i}}{e^{\lambda_i} + e^{\lambda_j}} = \frac{1}{1 + e^{-(\lambda_i - \lambda_j)}}
$$

**Key Properties:**

- $\lambda_i$ represents the log-strength of team $i$
- Higher $\lambda$ indicates stronger team
- The model is invariant to additive constants (we fix one reference team at $\lambda = 0$)
- Win probability depends only on the **difference** $\lambda_i - \lambda_j$

### Advantages for Tournament Analysis

1. **Handles incomplete matchups:** Not every team plays every other team
2. **Strength transitivity:** If A beats B and B beats C, model appropriately adjusts A's advantage over C
3. **Uncertainty quantification:** Standard errors on $\lambda$ estimates allow confidence intervals
4. **Probabilistic predictions:** Naturally produces win probabilities for any matchup

### Model Fitting

We fit the Bradley-Terry model using maximum likelihood estimation via the `BradleyTerry2` R package. The log-likelihood for $n$ games is:

$$
\ell(\lambda) = \sum_{k=1}^{n} \left[ \lambda_{i_k} - \log(e^{\lambda_{i_k}} + e^{\lambda_{j_k}}) \right]
$$

where game $k$ was won by team $i_k$ over team $j_k$.

We fit **separate Bradley-Terry models for each season**, then aggregate results using inverse-variance weighting. This approach accounts for year-to-year variation while providing stable estimates:

```{r bt-model-fitting-code, eval=FALSE}
library(BradleyTerry2)

# Load prepared data
bt_data <- readRDS(here("data", "processed", "bt_data.rds"))

# Fit separate models for each season
seasons <- sort(unique(bt_data$season))
all_season_abilities <- list()

for (season_year in seasons) {
    # Filter data for this season
    bt_season <- bt_data %>% filter(season == season_year)

    # Fit Bradley-Terry model for this season
    bt_model_season <- BradleyTerry2::BTm(
        outcome = cbind(home.wins, away.wins),
        player1 = home.team,
        player2 = away.team,
        formula = ~ team + home_adv_bar, # Home advantage covariate
        id = "team",
        contrasts = list(team = "contr.sum"),
        data = bt_season
    )

    # Extract abilities
    abilities_season <- BradleyTerry2::BTabilities(bt_model_season) %>%
        as.data.frame() %>%
        rownames_to_column(var = "team") %>%
        rename(lambda = ability, se = s.e.) %>%
        mutate(season = season_year)

    all_season_abilities[[as.character(season_year)]] <- abilities_season
}

# Aggregate abilities across seasons using inverse-variance weighting
all_abilities <- bind_rows(all_season_abilities)

team_abilities_df <- all_abilities %>%
    mutate(se = pmax(se, 1e-6)) %>% # Prevent division by zero
    group_by(team) %>%
    summarise(
        lambda = weighted.mean(lambda, w = 1 / (se^2), na.rm = TRUE),
        se = sqrt(1 / sum(1 / (se^2), na.rm = TRUE)),
        n_seasons = n(),
        .groups = "drop"
    ) %>%
    arrange(desc(lambda))

# Add tournament seeding information
team_abilities_with_seeds <- team_abilities_df %>%
    left_join(tournament_seeds %>% select(team, seed, region), by = "team") %>%
    mutate(
        is_mid_tier_seed = !is.na(seed) & seed >= 8 & seed <= 12,
        seed_category = case_when(
            is.na(seed) ~ "Non-tournament",
            seed <= 4 ~ "1-4 seeds",
            seed <= 7 ~ "5-7 seeds",
            seed <= 12 ~ "8-12 seeds",
            TRUE ~ "13-16 seeds"
        )
    )

# Compute win probability matrix for all pairs (neutral site)
lambda_vec <- setNames(team_abilities_df$lambda, team_abilities_df$team)
lambda_diff <- outer(X = lambda_vec, Y = lambda_vec, FUN = "-")
win_probs <- 1 / (1 + exp(-1 * lambda_diff))
win_probs <- pmin(pmax(win_probs, 1e-6), 1 - 1e-6) # Numerical stability
diag(win_probs) <- NA # Teams don't play themselves

# Save results
saveRDS(bt_model, here("data", "processed", "bt_model.rds"))
saveRDS(
    team_abilities_with_seeds,
    here("data", "processed", "team_abilities_with_seeds.rds")
)
saveRDS(win_probs, here("data", "processed", "win_probability_matrix.rds"))
```

## 2.2 Data

```{r data-summary, echo=FALSE}
# Load data info
team_abilities <- read_if_exists(here("data", "processed", "team_abilities_with_seeds.rds"))
games_cleaned <- read_if_exists(here("data", "processed", "games_cleaned.rds"))

if (!is.null(team_abilities) && !is.null(games_cleaned)) {
    n_teams <- nrow(team_abilities)
    n_games <- nrow(games_cleaned)
    n_tournament_teams <- sum(!is.na(team_abilities$seed))
    n_mid_tier <- sum(team_abilities$seed >= 8 & team_abilities$seed <= 12, na.rm = TRUE)
} else {
    n_teams <- NA
    n_games <- NA
    n_tournament_teams <- NA
    n_mid_tier <- NA
}
```

### Data Source and Collection

**Source:** Women's NCAA Basketball data via the `wehoop` R package

**Scope:** Regular season games from 2019, 2021-2024 seasons (5 seasons total)
  - Note: 2020 season excluded due to COVID-19 disruptions
  - Multi-season data provides more robust team strength estimates
  - Separate Bradley-Terry models fit per season, then aggregated

**Dataset Statistics:**

- Total teams analyzed: `r if(!is.na(n_teams)) n_teams else "N/A"`
- Total games: `r if(!is.na(n_games)) n_games else "N/A"`
- Tournament teams: `r if(!is.na(n_tournament_teams)) n_tournament_teams else "N/A"`
- Teams with 8-12 seeds: `r if(!is.na(n_mid_tier)) n_mid_tier else "N/A"`

### Data Collection Process

We begin by loading game schedules for five seasons (2019, 2021-2024). The `wehoop` package provides comprehensive game-level data from ESPN, including scores, dates, and team identifiers.

```{r data-collection-code, eval=FALSE}
suppressPackageStartupMessages({
    library(tidyverse)
    library(lubridate)
    library(here)
    library(wehoop)
    library(igraph)
})

# Expanded to include more seasons for robust model estimation
# Using 2019-2024 (5 seasons) - skipping 2020 due to COVID disruptions
SEASONS <- c(2019, 2021, 2022, 2023, 2024)
set.seed(479)

# Load raw data from wehoop
raw <- wehoop::load_wbb_schedule(seasons = SEASONS)
stopifnot(is.data.frame(raw), nrow(raw) > 0)

# Helper function to pick first available column name
# (wehoop schema may vary across versions)
pick_first <- function(cands, nm) {
    hit <- intersect(cands, nm)
    if (length(hit)) hit[1] else NA_character_
}

# Map column names flexibly
nm <- names(raw)
date_col <- pick_first(c("game_date", "start_date", "date"), nm)
season_col <- pick_first(c("season", "season_year"), nm)
id_col <- pick_first(c("game_id", "id", "espn_game_id"), nm)
home_team_col <- pick_first(c("home_display_name", "home_name", "home_location"), nm)
away_team_col <- pick_first(c("away_display_name", "away_name", "away_location"), nm)
home_score_col <- pick_first(c("home_score", "home_points"), nm)
away_score_col <- pick_first(c("away_score", "away_points"), nm)
neutral_col <- pick_first(c("neutral_site", "neutral"), nm)
type_col <- pick_first(c("season_type", "game_type"), nm)

# Transform to standardized format
games_combined <- raw |>
    transmute(
        game_id = if (!is.na(id_col)) as.character(.data[[id_col]]) else NA_character_,
        season = suppressWarnings(as.integer(.data[[season_col]])),
        game_date = suppressWarnings(lubridate::ymd(.data[[date_col]])),
        home_team = as.character(.data[[home_team_col]]),
        away_team = as.character(.data[[away_team_col]]),
        home_score = if (!is.na(home_score_col)) {
            suppressWarnings(as.integer(.data[[home_score_col]]))
        } else {
            NA_integer_
        },
        away_score = if (!is.na(away_score_col)) {
            suppressWarnings(as.integer(.data[[away_score_col]]))
        } else {
            NA_integer_
        },
        neutral_site = if (!is.na(neutral_col)) {
            val <- .data[[neutral_col]]
            as.integer(val %in% c(TRUE, 1, "1", "TRUE"))
        } else {
            0L
        },
        season_type = if (!is.na(type_col)) .data[[type_col]] else NA
    ) |>
    distinct(game_id, .keep_all = TRUE)
```

After loading, we apply D-I team normalization **before any filtering** (critical fix), then filter for data quality:

```{r data-filtering-code, eval=FALSE}
# ====== D-I NORMALIZATION (BEFORE ANY FILTERING) ======
# This ensures only Division I vs Division I matchups
normalize_name <- function(x) stringr::str_squish(stringr::str_to_lower(x))

d1_teams <- tryCatch(
    suppressMessages(purrr::map_dfr(SEASONS, wehoop::espn_wbb_teams)),
    error = function(e) NULL
)

wbb_di <- d1_teams |>
    filter(
        is.na(classification) | str_detect(tolower(classification), "ncaa"),
        is.na(division) | str_detect(tolower(division), "^(1|i|division i)")
    ) |>
    transmute(di_team = display_name, di_key = normalize_name(display_name)) |>
    distinct()

# Apply D-I filtering to games_combined FIRST
games_norm <- games_combined |>
    mutate(
        home_key = normalize_name(home_team),
        away_key = normalize_name(away_team)
    ) |>
    left_join(wbb_di, by = c("home_key" = "di_key")) |>
    rename(home_di_team = di_team) |>
    left_join(wbb_di, by = c("away_key" = "di_key")) |>
    rename(away_di_team = di_team) |>
    filter(!is.na(home_di_team), !is.na(away_di_team)) |>
    mutate(home_team = home_di_team, away_team = away_di_team)

# ====== REGULAR-SEASON FILTER (IMPROVED) ======
# Coerce season_type and handle both numeric and text
stype <- suppressWarnings(as.integer(games_norm$season_type))

if (!all(is.na(stype)) && any(stype == 2, na.rm = TRUE)) {
    games_cleaned <- games_norm |> filter(stype == 2)
} else {
    # Text or missing: use text matching + date fallback
    stxt <- tolower(as.character(games_norm$season_type))
    games_cleaned <- games_norm |>
        filter(str_detect(stxt, "regular") |
            (!str_detect(stxt, "post|tourn|conf") & month(game_date) <= 2))
}

# Keep only completed games with valid scores, no ties
games_cleaned <- games_cleaned |>
    filter(!is.na(home_score), !is.na(away_score)) |>
    filter(home_score >= 0, away_score >= 0) |>
    filter(!is.na(game_date)) |>
    filter(home_score != away_score) |>
    mutate(
        home_winner = as.integer(home_score > away_score),
        away_winner = 1L - home_winner
    )

# Keep only largest connected component of matchup graph
# This ensures all teams are comparable through transitive relationships
g <- graph_from_data_frame(
    games_cleaned |> distinct(home_team, away_team),
    directed = FALSE
)
comps <- components(g)
largest_comp <- which.max(comps$csize)
teams_in_cc <- names(comps$membership[comps$membership == largest_comp])

games_cleaned <- games_cleaned |>
    filter(home_team %in% teams_in_cc, away_team %in% teams_in_cc)

# Filter teams with minimum 8 games (ensures stable estimates)
team_game_counts <- bind_rows(
    games_cleaned |> count(team = home_team, name = "n"),
    games_cleaned |> count(team = away_team, name = "n")
) |>
    group_by(team) |>
    summarise(total_games = sum(n), .groups = "drop")

eligible_teams <- team_game_counts |>
    filter(total_games >= 8) |>
    pull(team)

games_cleaned <- games_cleaned |>
    filter(home_team %in% eligible_teams, away_team %in% eligible_teams)
```

Finally, we prepare the data structure for Bradley-Terry model fitting:

```{r bt-data-prep-code, eval=FALSE}
# Create Bradley-Terry pair-wise comparison data
unique_teams <- sort(unique(c(games_cleaned$home_team, games_cleaned$away_team)))

bt_data <- games_cleaned |>
    rename(home.team = home_team, away.team = away_team) |>
    group_by(season, home.team, away.team) |>
    summarise(
        home.wins = sum(home_winner),
        away.wins = sum(away_winner),
        total_games = dplyr::n(),
        home_adv_bar = mean(1L - neutral_site), # Proportion played at home
        .groups = "drop"
    ) |>
    mutate(
        home.team = factor(home.team, levels = unique_teams),
        away.team = factor(away.team, levels = unique_teams)
    )

# Save processed data
dir.create(here("data", "processed"), recursive = TRUE, showWarnings = FALSE)
saveRDS(games_cleaned, here("data", "processed", "games_cleaned.rds"))
saveRDS(bt_data, here("data", "processed", "bt_data.rds"))
```

### Important Note: Model-Based Seeding

This analysis uses **model-based seeding** derived from Bradley-Terry lambda values, **not actual NCAA committee seeds**. 

- Seeds are assigned by ranking the top 64 teams by their aggregated Bradley-Terry strength (λ)
- This accounts for opponent-adjusted strength, not just raw win percentage
- Seed-specific matchup probabilities (e.g., "8 vs 9 seed") are **model-based what-if scenarios**, not historical reproductions
- To use real NCAA tournament data, replace `tournament_seeds.csv` with actual bracket assignments

**Key Improvement:** Lambda-based seeding is more accurate than win-percentage seeding because it accounts for strength of schedule. For example, a team with 20 wins against weak opponents gets a lower seed than a team with 20 wins against strong opponents.

**Interpretation:** Results should be viewed as **strength-based projections** rather than literal predictions of specific NCAA tournament matchups.

## 2.3 Analysis Approach

Our analysis consists of three complementary components:

### 1. Bradley-Terry Model Estimation

Fit latent team strength parameters $\lambda_i$ for all Division I teams using regular season game data.

**Output:** Team strength estimates with standard errors

### 2. Analytical Probability Calculations

For each tournament matchup, calculate exact win probabilities using:

$$
P(\text{win}) = \frac{1}{1 + e^{-(\lambda_i - \lambda_j)}}
$$

We implement this analytically for all 8-12 seed matchups:

```{r analytical-probabilities-code, eval=FALSE}
# Load team abilities
team_abilities <- readRDS(here("data", "processed", "team_abilities_with_seeds.rds"))

# Identify 8-12 seed teams
mid_tier_teams <- team_abilities %>%
    filter(seed >= 8 & seed <= 12) %>%
    arrange(seed, desc(lambda))

# First round matchups (standard NCAA bracket structure)
matchup_map <- tibble(
    seed = c(8, 9, 10, 11, 12),
    opponent_seed = c(9, 8, 7, 6, 5)
)

# Calculate first round win probabilities
first_round_analysis <- mid_tier_teams %>%
    left_join(matchup_map, by = "seed") %>%
    rowwise() %>%
    mutate(
        opponent_lambda = {
            opponent_team <- team_abilities %>%
                filter(seed == opponent_seed, region == region) %>%
                pull(lambda)
            if (length(opponent_team) > 0) opponent_team[1] else NA_real_
        },
        prob_win_round1 = if_else(
            !is.na(opponent_lambda),
            1 / (1 + exp(-(lambda - opponent_lambda))),
            NA_real_
        )
    ) %>%
    ungroup()

# Second round opponents (after winning R1)
second_round_matchups <- tibble(
    seed = c(8, 9, 10, 11, 12),
    r2_opponent_seed = c(1, 1, 2, 3, 4) # Typical top seeds
)

# Calculate Sweet 16 probabilities
second_round_analysis <- first_round_analysis %>%
    left_join(second_round_matchups, by = "seed") %>%
    rowwise() %>%
    mutate(
        r2_opponent_lambda = {
            opponent_team <- team_abilities %>%
                filter(seed == r2_opponent_seed, region == region) %>%
                pull(lambda)
            if (length(opponent_team) > 0) opponent_team[1] else NA_real_
        },
        prob_win_round2_conditional = if_else(
            !is.na(r2_opponent_lambda),
            1 / (1 + exp(-(lambda - r2_opponent_lambda))),
            NA_real_
        ),
        prob_reach_sweet16 = prob_win_round1 * prob_win_round2_conditional
    ) %>%
    ungroup()

# Expected number in Sweet 16
expected_in_sweet16 <- sum(second_round_analysis$prob_reach_sweet16, na.rm = TRUE)

# Calculate deeper run probabilities
top_seed_abilities <- team_abilities %>%
    filter(seed <= 4) %>%
    group_by(region) %>%
    summarise(avg_top_lambda = mean(lambda, na.rm = TRUE))

deeper_runs <- second_round_analysis %>%
    left_join(top_seed_abilities, by = "region") %>%
    mutate(
        prob_win_sweet16 = 1 / (1 + exp(-(lambda - avg_top_lambda))),
        prob_reach_elite8 = prob_reach_sweet16 * prob_win_sweet16,
        prob_win_elite8 = 1 / (1 + exp(-(lambda - avg_top_lambda - 0.5))),
        prob_reach_final4 = prob_reach_elite8 * prob_win_elite8,
        prob_win_final4 = 1 / (1 + exp(-(lambda - avg_top_lambda - 0.5))),
        prob_reach_finals = prob_reach_final4 * prob_win_final4,
        prob_win_championship = 1 / (1 + exp(-(lambda - avg_top_lambda - 0.5))),
        prob_win_title = prob_reach_finals * prob_win_championship
    )

# Conditional probabilities (given Sweet 16 appearance)
conditional_probs <- deeper_runs %>%
    mutate(
        prob_elite8_given_sweet16 = prob_reach_elite8 / prob_reach_sweet16,
        prob_final4_given_sweet16 = prob_reach_final4 / prob_reach_sweet16,
        prob_finals_given_sweet16 = prob_reach_finals / prob_reach_sweet16,
        prob_champion_given_sweet16 = prob_win_title / prob_reach_sweet16
    )

overall_conditional <- conditional_probs %>%
    summarise(
        prob_elite8_given_s16 = weighted.mean(prob_elite8_given_sweet16,
            prob_reach_sweet16,
            na.rm = TRUE
        ),
        prob_final4_given_s16 = weighted.mean(prob_final4_given_sweet16,
            prob_reach_sweet16,
            na.rm = TRUE
        ),
        prob_champion_given_s16 = weighted.mean(prob_champion_given_sweet16,
            prob_reach_sweet16,
            na.rm = TRUE
        )
    )

# Save results
key_results <- list(
    expected_in_sweet16 = expected_in_sweet16,
    overall_conditional = overall_conditional
)
saveRDS(key_results, here("results", "tables", "key_results.rds"))
```

**Output:** Seed-level summary statistics and conditional probabilities

### 3. Monte Carlo Tournament Simulation

Simulate complete 64-team single-elimination tournaments 5,000 times using Bradley-Terry win probabilities.

We implement a fast, vectorized simulation function that processes entire rounds simultaneously:

```{r simulation-code, eval=FALSE}
library(parallel)

# Load team abilities
team_abilities <- readRDS(here("data", "processed", "team_abilities_with_seeds.rds"))

# Create lookup matrices for fast simulation
regions <- sort(unique(team_abilities$region))
lambda_mat <- matrix(NA_real_,
    nrow = length(regions), ncol = 16,
    dimnames = list(regions, as.character(1:16))
)
team_mat <- matrix(NA_character_,
    nrow = length(regions), ncol = 16,
    dimnames = list(regions, as.character(1:16))
)

# Fill matrices
tmp <- team_abilities %>%
    select(region, seed, team, lambda) %>%
    arrange(region, seed)
for (i in seq_len(nrow(tmp))) {
    rr <- as.character(tmp$region[i])
    ss <- as.character(tmp$seed[i])
    if (ss %in% colnames(lambda_mat) && rr %in% rownames(lambda_mat) &&
        is.na(lambda_mat[rr, ss])) {
        lambda_mat[rr, ss] <- tmp$lambda[i]
        team_mat[rr, ss] <- tmp$team[i]
    }
}

# Fast lookup functions
get_lambda_fast <- function(seed, region) lambda_mat[region, as.character(seed)]
get_team_fast <- function(seed, region) team_mat[region, as.character(seed)]
inv_logit <- function(x) 1 / (1 + exp(-x))

# Simulate single game
simulate_game <- function(team1_lambda, team2_lambda) {
    p <- inv_logit(team1_lambda - team2_lambda)
    p <- pmin(pmax(p, 1e-6), 1 - 1e-6) # Numerical stability
    rbinom(length(p), size = 1, prob = p)
}

# Simulate entire tournament
simulate_tournament_fast <- function(seed_val = NULL) {
    if (!is.null(seed_val)) set.seed(seed_val)

    # First round matchups
    hi <- c(1, 2, 3, 4, 5, 6, 7, 8)
    lo <- c(16, 15, 14, 13, 12, 11, 10, 9)

    out_rows <- list()

    # Simulate each region
    for (rr in rownames(lambda_mat)) {
        # Round of 64
        team1_l <- get_lambda_fast(hi, rr)
        team2_l <- get_lambda_fast(lo, rr)
        team1_n <- get_team_fast(hi, rr)
        team2_n <- get_team_fast(lo, rr)

        win1 <- simulate_game(team1_l, team2_l)
        r64_w_seed <- ifelse(win1 == 1, hi, lo)
        r64_w_l <- ifelse(win1 == 1, team1_l, team2_l)
        r64_w_n <- ifelse(win1 == 1, team1_n, team2_n)

        out_rows[[length(out_rows) + 1]] <- tibble(
            round = "Round of 64", region = rr,
            winner_seed = r64_w_seed, winner_lambda = r64_w_l, winner_name = r64_w_n
        )

        # Round of 32
        idx32 <- matrix(r64_w_seed, nrow = 2, byrow = TRUE)
        lam32 <- matrix(r64_w_l, nrow = 2, byrow = TRUE)
        nam32 <- matrix(r64_w_n, nrow = 2, byrow = TRUE)

        win2 <- simulate_game(lam32[1, ], lam32[2, ])
        r32_w_seed <- ifelse(win2 == 1, idx32[1, ], idx32[2, ])
        r32_w_l <- ifelse(win2 == 1, lam32[1, ], lam32[2, ])
        r32_w_n <- ifelse(win2 == 1, nam32[1, ], nam32[2, ])

        out_rows[[length(out_rows) + 1]] <- tibble(
            round = "Round of 32", region = rr,
            winner_seed = r32_w_seed, winner_lambda = r32_w_l, winner_name = r32_w_n
        )

        # Sweet 16
        idx16 <- matrix(r32_w_seed, nrow = 2, byrow = TRUE)
        lam16 <- matrix(r32_w_l, nrow = 2, byrow = TRUE)
        nam16 <- matrix(r32_w_n, nrow = 2, byrow = TRUE)

        win3 <- simulate_game(lam16[1, ], lam16[2, ])
        r16_w_seed <- ifelse(win3 == 1, idx16[1, ], idx16[2, ])
        r16_w_l <- ifelse(win3 == 1, lam16[1, ], lam16[2, ])
        r16_w_n <- ifelse(win3 == 1, nam16[1, ], nam16[2, ])

        out_rows[[length(out_rows) + 1]] <- tibble(
            round = "Sweet 16", region = rr,
            winner_seed = r16_w_seed, winner_lambda = r16_w_l, winner_name = r16_w_n
        )

        # Elite 8, Final Four, Championship follow similar pattern...
    }

    bind_rows(out_rows)
}

# Run 5,000 simulations in parallel
N_SIMS <- 5000
N_CORES <- max(1, detectCores() - 1)

simulation_results <- mclapply(
    X = 1:N_SIMS,
    FUN = function(sim) {
        simulate_tournament_fast(seed_val = 479 + sim) %>%
            mutate(sim_id = sim)
    },
    mc.cores = N_CORES
)

all_simulations <- bind_rows(simulation_results)

# Analyze 8-12 seed performance
round_order <- c(
    "Round of 64", "Round of 32", "Sweet 16",
    "Elite 8", "Final Four", "Championship"
)

mid_tier_counts <- all_simulations %>%
    mutate(round = factor(round, levels = round_order)) %>%
    group_by(sim_id, round) %>%
    summarise(n_mid_tier = sum(winner_seed >= 8 & winner_seed <= 12), .groups = "drop")

# Summary statistics
mid_tier_summary <- mid_tier_counts %>%
    group_by(round) %>%
    summarise(
        mean_count = mean(n_mid_tier),
        median_count = median(n_mid_tier),
        sd_count = sd(n_mid_tier),
        min_count = min(n_mid_tier),
        max_count = max(n_mid_tier)
    )

# Save results
saveRDS(all_simulations, here("results", "tables", "all_simulations.rds"))
saveRDS(mid_tier_summary, here("results", "tables", "simulation_summary.rds"))
```

**Output:** Empirical distributions of 8-12 seed advancement by round, conditional probabilities, validation of analytical estimates

### Why Both Analytical and Simulation?

- **Analytical:** Exact for simple probabilities (first round), computationally efficient
- **Simulation:** Handles complex dependencies (later rounds depend on earlier upsets), provides distributional information
- **Cross-validation:** Agreement between methods validates model assumptions

## 2.4 Computational Details

- **Software:** R 4.x
- **Key Packages:** `tidyverse`, `BradleyTerry2`, `wehoop`, `here`
- **Simulations:** 5,000 Monte Carlo replications
- **Random Seeds:** Set for reproducibility (`set.seed(479 + iteration)`)
- **Hardware:** Standard laptop (simulations complete in ~5-10 minutes)

---

# 3. Results

## 3.1 Team Strength Estimates

```{r team-strength-plot, echo=FALSE, fig.cap="Team strength distribution by seed category"}
knitr::include_graphics(here("results", "figures", "01_team_strength_by_seed.png"))
```

The Bradley-Terry model successfully distinguishes between seed categories, with higher seeds showing systematically higher estimated strengths. The strength parameter $\lambda$ exhibits clear separation:

- **Seeds 1-4:** $\lambda > 8$ (strongest teams)
- **Seeds 5-7:** $6 < \lambda < 8$ (strong teams)
- **Seeds 8-12:** $4 < \lambda < 6$ (mid-tier teams, our focus)
- **Seeds 13-16:** $\lambda < 4$ (weakest tournament teams)

This ordering validates that regular season performance (which determines seeds) correlates strongly with model-estimated strength.

### Top 10 Strongest Teams

```{r top-teams, echo=FALSE}
if (!is.null(team_abilities)) {
    top_teams <- team_abilities %>%
        filter(!is.na(seed)) %>%
        arrange(desc(lambda)) %>%
        head(10) %>%
        select(
            Team = team, Seed = seed, Region = region,
            Lambda = lambda, `Std. Error` = se
        ) %>%
        mutate(
            Lambda = sprintf("%.3f", Lambda),
            `Std. Error` = sprintf("%.3f", `Std. Error`)
        )

    kable(top_teams, caption = "Top 10 Strongest Teams (Lambda = log-strength on Bradley-Terry scale)") %>%
        kable_styling(bootstrap_options = c("striped", "hover"))
}
```

All top-10 teams are seeded 1-4, confirming that the selection committee's seeding aligns with regular season strength. The standard errors (SE) are relatively small, indicating precise strength estimates.

### Strength Across All Tournament Teams

```{r all-teams-plot, echo=FALSE, fig.cap="Bradley-Terry strength estimates for all 64 tournament teams"}
knitr::include_graphics(here("results", "figures", "02_all_team_strengths.png"))
```

## 3.2 First Round Performance (8-12 Seeds)

```{r first-round-plot, echo=FALSE, fig.cap="First round win probabilities for 8-12 seeds"}
knitr::include_graphics(here("results", "figures", "03_first_round_probabilities.png"))
```

```{r first-round-table, echo=FALSE}
if (!is.null(key_results) && !is.null(key_results$first_round_summary)) {
    first_round_summary <- key_results$first_round_summary %>%
        select(
            Seed = seed, `N Teams` = n_teams,
            `Avg Win Prob` = avg_prob_win, `Expected Wins` = expected_wins
        ) %>%
        mutate(
            `Avg Win Prob` = sprintf("%.1f%%", `Avg Win Prob` * 100),
            `Expected Wins` = sprintf("%.2f", `Expected Wins`)
        )

    kable(first_round_summary,
        caption = "First Round Win Probabilities by Seed"
    ) %>%
        kable_styling(bootstrap_options = c("striped", "hover"))
}
```

**Key Findings:**

- **8 seeds** face 9 seeds (near-even matchup): ~49% win probability
- **9 seeds** face 8 seeds (near-even matchup): ~51% win probability  
- **10 seeds** face 7 seeds: ~34% win probability
- **11 seeds** face 6 seeds: ~32% win probability
- **12 seeds** face 5 seeds: ~25% win probability

Collectively, we expect about **9-10 of the 20 teams seeded 8-12 to win their first-round game**.

## 3.3 Research Question 1: Expected Advancement

```{r advancement-plot, echo=FALSE, fig.cap="Expected number of 8-12 seeds advancing by round"}
knitr::include_graphics(here("results", "figures", "04_expected_advancement.png"))
```

```{r analytical-vs-sim, echo=FALSE, fig.cap="Comparison of analytical predictions with Monte Carlo simulation results"}
knitr::include_graphics(here("results", "figures", "06_analytical_vs_simulation.png"))
```

### Answer to Research Question 1

**We expect approximately `r if(!is.null(key_results)) sprintf("%.2f", key_results$expected_in_sweet16) else "1.72"` of the 8-12 seeds to advance to the Sweet 16** in a typical tournament.

- **Analytical calculation:** 1.72 teams
- **Simulation mean:** 1.68 teams (from 5,000 simulations)
- **Typical range:** 0-4 teams (95% of simulations)

```{r advancement-table, echo=FALSE}
if (!is.null(key_results) && !is.null(key_results$second_round_summary)) {
    advancement <- key_results$second_round_summary %>%
        select(
            Seed = seed, `N Teams` = n_teams,
            `P(Round 2 Win | Round 1 Win)` = avg_prob_win_r2_conditional,
            `P(Sweet 16)` = avg_prob_reach_sweet16,
            `Expected in Sweet 16` = expected_in_sweet16
        ) %>%
        mutate(
            `P(Round 2 Win | Round 1 Win)` = sprintf(
                "%.1f%%",
                `P(Round 2 Win | Round 1 Win)` * 100
            ),
            `P(Sweet 16)` = sprintf("%.1f%%", `P(Sweet 16)` * 100),
            `Expected in Sweet 16` = sprintf("%.2f", `Expected in Sweet 16`)
        )

    kable(advancement,
        caption = "Second Round Performance and Sweet 16 Expectations (R1 = Round 1, R2 = Round 2)"
    ) %>%
        kable_styling(bootstrap_options = c("striped", "hover"))
}
```

**Key Insights:**

- Even if an 8 or 9 seed wins Round 1, they face a top seed (1 or 2) in Round 2, dramatically lowering Sweet 16 probability
- 10-12 seeds face 3-5 seeds in Round 2 if they advance—still challenging but slightly better odds than 8-9 seeds
- The "expected in Sweet 16" column shows that each seed contributes less than 0.5 teams on average

## 3.4 Research Question 2: Conditional Probabilities

```{r conditional-plot, echo=FALSE, fig.cap="Conditional probabilities given Sweet 16 appearance"}
knitr::include_graphics(here("results", "figures", "07_conditional_probabilities.png"))
```

### Answer to Research Question 2

**Given that an 8-12 seed reaches the Sweet 16:**

- Probability of reaching **Elite 8**: `r if(!is.null(key_results)) sprintf("%.1f%%", key_results$overall_conditional$prob_elite8_given_s16 * 100) else "45.7%"`
- Probability of reaching **Final Four**: `r if(!is.null(key_results)) sprintf("%.1f%%", key_results$overall_conditional$prob_final4_given_s16 * 100) else "18.7%"`
- Probability of reaching **Finals**: `r if(!is.null(key_results)) sprintf("%.1f%%", key_results$overall_conditional$prob_finals_given_s16 * 100) else "8.8%"`
- Probability of **winning championship**: `r if(!is.null(key_results)) sprintf("%.1f%%", key_results$overall_conditional$prob_champion_given_s16 * 100) else "3.7%"`

```{r conditional-table, echo=FALSE}
if (!is.null(key_results) && !is.null(key_results$conditional_summary)) {
    conditional <- key_results$conditional_summary %>%
        select(
            Seed = seed,
            `P(Elite 8 | Sweet 16)` = avg_prob_elite8_given_s16,
            `P(Final Four | Sweet 16)` = avg_prob_final4_given_s16,
            `P(Finals | Sweet 16)` = avg_prob_finals_given_s16,
            `P(Champion | Sweet 16)` = avg_prob_champion_given_s16
        ) %>%
        mutate(across(where(is.numeric), ~ sprintf("%.1f%%", . * 100)))

    kable(conditional,
        caption = "Conditional Advancement Probabilities by Seed (Given Sweet 16)"
    ) %>%
        kable_styling(bootstrap_options = c("striped", "hover"))
}
```

**Interpretation:**

- Making the Sweet 16 as an 8-12 seed suggests the team has already beaten better-than-expected opponents
- However, subsequent rounds still present formidable challenges (typically 1-3 seeds)
- Only about 1 in 27 teams (3.7%) that reach the Sweet 16 go on to win the championship
- The conditional probabilities are higher for 8-9 seeds than 10-12 seeds, reflecting their slightly stronger regular season performance

## 3.5 Monte Carlo Simulation Results

```{r simulation-plot, echo=FALSE, fig.cap="Distribution of 8-12 seeds by round (5000 simulations)"}
knitr::include_graphics(here("results", "figures", "05_simulation_distributions.png"))
```

### Simulation Validation

The Monte Carlo simulations (5,000 tournament replications) closely match our analytical predictions, providing confidence in our results. The distributions show substantial variation—some tournaments have no mid-tier seeds in the Sweet 16, while others have 3-4.

```{r heatmap, echo=FALSE, fig.cap="Seed performance heatmap from simulations"}
knitr::include_graphics(here("results", "figures", "08_seed_performance_heatmap.png"))
```

```{r simulation-summary, echo=FALSE}
if (!is.null(key_results) && !is.null(key_results$simulation_summary)) {
    sim_summary <- key_results$simulation_summary %>%
        filter(round %in% c("Sweet 16", "Elite 8", "Final Four", "Championship")) %>%
        select(
            Round = round,
            `Mean Count` = mean_count,
            `Median Count` = median_count,
            `SD` = sd_count,
            `Min` = min_count,
            `Max` = max_count,
            `P(Zero)` = prob_zero
        ) %>%
        mutate(
            `Mean Count` = round(`Mean Count`, 2),
            `SD` = round(`SD`, 2),
            `P(Zero)` = sprintf("%.1f%%", `P(Zero)` * 100)
        )

    kable(sim_summary,
        caption = "8-12 Seed Counts by Round (5,000 Simulations). P(Zero) = probability of zero 8-12 seeds reaching that round"
    ) %>%
        kable_styling(bootstrap_options = c("striped", "hover"))
}
```

## 3.6 Individual Team Probabilities

```{r load-individual-results, echo=FALSE}
# Load individual team probability results
team_probs <- read_if_exists(here("results", "tables", "individual_team_probabilities.rds"))
mid_tier_advancement <- read_if_exists(here("results", "tables", "mid_tier_team_advancement.csv"))
```

While the previous sections analyzed 8-12 seeds as a group, we can also calculate the probability that **specific teams** make it to each round. This is particularly relevant given that in 2023 and 2024, **no 8-12 seeds made it to the Sweet 16**.

### Sweet 16 Probabilities by Team

```{r sweet16-individual-plot, echo=FALSE, fig.cap="Individual team probabilities of reaching Sweet 16"}
knitr::include_graphics(here("results", "figures", "09_sweet16_mid_tier_probabilities.png"))
```

```{r sweet16-team-table, echo=FALSE}
if (!is.null(mid_tier_advancement)) {
    sweet16_teams <- mid_tier_advancement %>%
        arrange(desc(`Sweet 16`)) %>%
        select(
            Team = winner_name,
            Seed = seed,
            Region = region,
            `P(Sweet 16)` = `Sweet 16`,
            `P(Elite 8)` = `Elite 8`,
            `P(Final Four)` = `Final Four`
        ) %>%
        mutate(across(where(is.numeric), ~ sprintf("%.1f%%", . * 100)))

    kable(sweet16_teams,
        caption = "Individual 8-12 Seed Team Probabilities"
    ) %>%
        kable_styling(bootstrap_options = c("striped", "hover"))
}
```

### Key Findings

- **Stanford Cardinal (11-seed)** has the highest Sweet 16 probability at **62.5%**—unusually high for an 11-seed
- **Indiana Hoosiers (8-seed)** follows with **48.5%** probability
- **Michigan Wolverines (8-seed)** at **47.8%**
- Substantial within-seed variation exists: not all 8-seeds are equivalent

### Round-by-Round Progression

```{r progression-plot, echo=FALSE, fig.cap="Round-by-round progression for top 8-12 seeds"}
knitr::include_graphics(here("results", "figures", "10_round_by_round_progression.png"))
```

The chart above shows how the top five 8-12 seeds by Sweet 16 probability progress through each tournament round. Note the steep decline after the Sweet 16, as these teams face increasingly difficult opponents.

### Comprehensive Probability Heatmap

```{r probability-heatmap, echo=FALSE, fig.cap="Heatmap of all 8-12 seed probabilities by round"}
knitr::include_graphics(here("results", "figures", "11_probability_heatmap.png"))
```

This heatmap visualizes all 8-12 seed teams' probabilities across tournament rounds, showing both seed-level patterns and individual team variation.

## 3.7 Historical Context: 2023-2024 Results

```{r historical-context-plot, echo=FALSE, fig.cap="Model predictions vs. observed 2023-2024 results"}
knitr::include_graphics(here("results", "figures", "12_expected_vs_observed.png"))
```

Our model predicts approximately **1.72 8-12 seeds** should reach the Sweet 16 on average. However, in both 2023 and 2024, **zero 8-12 seeds** reached the Sweet 16.

**Statistical Context:**

- Expected number of 8-12 seeds in Sweet 16: **1.72**
- Probability of zero 8-12 seeds reaching Sweet 16: **17.9%**
- **Interpretation:** Roughly a **1-in-6 chance**—unusual but not unprecedented

This suggests the 2023-2024 results were somewhat unusual but **not impossible** - such outcomes can occur due to:

- Random variation (bracket "busts")
- Particularly strong performances by top seeds
- Injuries or other factors not captured in regular season data

### Spotlight: Stanford Cardinal

```{r stanford-spotlight, echo=FALSE, fig.cap="Stanford Cardinal tournament probabilities"}
knitr::include_graphics(here("results", "figures", "13_stanford_spotlight.png"))
```

As an example of individual team analysis, Stanford Cardinal (11-seed, Spokane Region) shows:

- **81.0%** chance of winning Round of 64
- **70.8%** chance of reaching Round of 32
- **62.5%** chance of reaching Sweet 16
- **15.2%** chance of reaching Elite 8
- **4.6%** chance of reaching Final Four

Despite being an 11-seed, Stanford's strong regular season performance (λ = 5.37) gives them elite-8-seed-level probabilities in the early rounds. Stanford's case illustrates why individual team analysis matters: despite being seeded 11th, their Bradley-Terry strength estimate exceeds many 8-9 seeds, resulting in substantially higher advancement probabilities.

---

# 4. Discussion

## 4.1 Summary of Key Findings

### Aggregate-Level Insights

1. **Expected Sweet 16 Advancement:** Approximately 1.72 teams seeded 8-12 reach the Sweet 16 in a typical tournament (range: 0-4)

2. **Conditional Deep Runs:** An 8-12 seed that reaches the Sweet 16 has:
   - 45.7% chance of Elite 8
   - 18.7% chance of Final Four
   - 8.8% chance of Championship game
   - 3.7% chance of winning it all

3. **Model Validation:** Strong agreement between analytical calculations and Monte Carlo simulations confirms model robustness

### Individual-Level Insights

4. **Substantial Within-Seed Variation:** Individual team strength matters significantly beyond seed number alone
   - Stanford (11-seed): 62.5% Sweet 16 probability
   - Some 12-seeds: <20% Sweet 16 probability

5. **Historical Contextualization:** The 2023-2024 outcome (zero 8-12 seeds in Sweet 16) has 17.9% probability—unusual but not shocking

## 4.2 Interpretation and Implications

### For Bracket Predictions

- **Don't Over-Predict Upsets:** Expect only 1-2 mid-tier seeds to reach Sweet 16, not 4-5
- **Use Team-Specific Data:** Look beyond seed numbers to regular season strength metrics
- **Identify Cinderella Candidates:** Teams like Stanford with high λ values despite lower seeds are prime upset picks

### For Sports Media and Fans

- **Calibrate Expectations:** When a 10-seed makes the Elite 8, that's genuinely rare (~5-10% occurrence)
- **Understand Variance:** Back-to-back "chalk" tournaments (like 2023-2024) happen naturally about once every 5-6 years
- **Individual Team Stories:** Focus on specific teams' strengths rather than seed generalizations

### For Teams and Coaches

- **Regular Season Matters:** Stronger regular season performance measurably increases tournament advancement probability even within the same seed tier
- **Matchup-Specific Preparation:** A 9-seed facing an 8-seed has near 50-50 odds; a 12-seed facing a 5-seed has ~25% odds—very different competitive scenarios
- **Seeding Implications:** Being seeded 8 vs. 10 makes a meaningful difference in expected tournament outcomes

## 4.3 Limitations and Considerations

### Model Limitations

1. **Constant Strength Assumption:** The model assumes team strength remains constant from regular season through tournament. In reality:
   - Injuries can dramatically alter team composition
   - Player fatigue accumulates
   - Teams may "peak" at different times

2. **No Momentum Effects:** The model treats each game independently. Some evidence suggests:
   - Teams on "hot streaks" may outperform expectations
   - Previous round upsets might build confidence

3. **Neutral Site Assumption:** While NCAA tournament games are nominally neutral site:
   - Geographic proximity may create pseudo-home-court advantages
   - Fan attendance patterns can favor certain teams

4. **Incomplete Opponent Information:** Regular season schedules vary in strength—not all 20-5 records are equivalent

### Data Limitations

1. **Single Season Data:** We use 2023-2024 season data only. Multi-year models might be more robust but complicate team roster continuity issues.

2. **Synthetic Seeding:** Our tournament bracket uses win%-based seeding rather than actual NCAA selection committee decisions, which incorporate:
   - Strength of schedule adjustments
   - Conference tournament results
   - Head-to-head records
   - Subjective evaluations of team quality

3. **No Tournament-Specific Data:** We exclude NCAA tournament games from model fitting (to avoid circular reasoning), but tournament performance might reveal team qualities not visible in regular season.

### Methodological Considerations

1. **Binary Win/Loss Only:** The Bradley-Terry model treats a 1-point win the same as a 30-point blowout. Margin-of-victory extensions exist but add complexity.

2. **No Contextual Variables:** The model doesn't account for:
   - Home court advantage in regular season (could inflate home team λ estimates)
   - Rest days between games
   - Player availability

3. **Independence Assumption:** Our simulation assumes win probabilities depend only on team strengths, ignoring potential correlation (e.g., teams from same conference may have correlated performance due to similar playing styles).

## 4.4 Future Directions

### Short-Term Enhancements

1. **Incorporate Actual NCAA Seeds:** Replace synthetic seeding with real NCAA committee selections once bracket is released

2. **Strength of Schedule Adjustments:** Weight team strength estimates by opponent quality

3. **Confidence Intervals:** Propagate uncertainty in λ estimates through tournament simulations

### Medium-Term Extensions

1. **Margin of Victory Models:** Extend to predict not just win/loss but score differentials

2. **Player-Level Data:** Incorporate individual player statistics to handle roster changes and injuries

3. **Time-Varying Strength:** Allow team strength to evolve across the season (early-season vs. late-season weights)

4. **Home Court Adjustment:** Model home advantage in regular season games, then remove for neutral-site tournament

### Long-Term Research

1. **Multi-Year Historical Analysis:** Validate model predictions against historical tournament outcomes (requires compiling multi-year datasets)

2. **Upset Predictor Features:** Identify characteristics beyond seed that predict upset propensity (e.g., pace of play, three-point shooting variance)

3. **Cross-Sport Generalization:** Apply methodology to men's basketball, other NCAA tournaments (hockey, soccer, etc.)

4. **Real-Time Updating:** Develop live tournament probability updates as each game concludes

## 4.5 Practical Applications

### Bracket Strategy Recommendations

Based on our findings, here are evidence-based bracketing strategies:

1. **Sweet 16 Picks:** Select 1-2 teams seeded 8-12, not 4-5. Prioritize:
   - Teams with high λ estimates relative to seed
   - 8-9 seeds over 11-12 seeds (better first-round odds)
   - Teams with favorable regional brackets

2. **Elite 8 Picks:** Be very conservative with 8-12 seeds at this stage. Consider at most one mid-tier seed reaching Elite 8.

3. **Upset Round Targeting:** Most 8-12 seed upsets happen in Round of 32 (beating the 1-2 seed) rather than first round. If picking a Cinderella run, ensure your chosen team:
   - Wins Round 1 (probability ~30-50% depending on seed)
   - Has a favorable Round 2 matchup (avoid strongest 1-seeds)

### Team Evaluation

For coaches, analysts, and fans evaluating team performance:

- **Over/Under-Seeded Detection:** Compare team's λ estimate to seed-typical λ range
  - Stanford (λ = 5.37, 11-seed) appears under-seeded
  - Look for similar discrepancies as value picks

- **Tournament Preparedness:** Teams with high λ estimates derived from strong regular season are statistically more likely to succeed, even if seeded lower

### Tournament Format Analysis

Our results quantify competitive balance in the current 64-team, 1-16 seeded format:

- **Sweet 16 Diversity:** Expect ~11-12 of 16 Sweet 16 teams to be seeded 1-4 (75%)
- **Mid-Tier Representation:** Only ~2 of 16 (12.5%) will be 8-12 seeds
- **Format Implications:** Current structure heavily favors top seeds. Alternative formats (e.g., reseeding after each round) would increase upset probability.

---

# 5. Conclusion

Using Bradley-Terry models combined with Monte Carlo simulation, we provide rigorous answers to our research questions:

1. **Approximately 1.7 of the 8-12 seeds should advance to the Sweet 16** in a typical tournament (range: 0-4)
2. **An 8-12 seed that reaches the Sweet 16 has an 18.7% probability of reaching the Final Four** and a 3.7% probability of winning the championship

Beyond these aggregate findings, our **individual team probability analysis** reveals:

- **Substantial within-seed variation:** Not all 8-seeds are equivalent. Teams like Stanford (11-seed, 62.5% Sweet 16 probability) substantially outperform seed-typical expectations based on regular season strength.

- **Historical context matters:** The 2023-2024 observation of zero 8-12 seeds in the Sweet 16 has a 17.9% probability under our model—unusual but expected about once every 5-6 years.

- **Model validation:** Strong agreement between analytical predictions and Monte Carlo simulations confirms the robustness of the Bradley-Terry modeling approach for tournament analysis.

## Methodological Contributions

This project demonstrates the power of combining classical statistical models (Bradley-Terry) with modern computational methods (Monte Carlo simulation) for sports analytics:

1. **Rigorous uncertainty quantification:** We provide not just point estimates but full probability distributions
2. **Multiple complementary approaches:** Analytical calculations validate simulation results
3. **Individual and aggregate insights:** Analysis works at both team-specific and seed-group levels
4. **Reproducible pipeline:** All code is documented and publicly available

## Final Thoughts

March Madness captures our imagination precisely because of its unpredictability. While 8-12 seeds face long odds for deep tournament runs, those runs *do* happen—just less frequently than casual fans might expect. Our model quantifies this tension between possibility and probability.

For practitioners, this work provides:
- **Bracket builders:** Evidence-based pick strategy
- **Media:** Context for evaluating upset significance  
- **Teams:** Motivation that regular season strength translates to tournament opportunity

For researchers, this work demonstrates sports analytics methodology that balances:
- Mathematical rigor (Bradley-Terry model theory)
- Computational validation (Monte Carlo simulation)
- Practical application (actionable tournament insights)

The 2023-2024 tournaments reminded us that even well-fitting models cannot perfectly predict single-elimination variance. But by understanding the *distribution* of possible outcomes, we can better appreciate when something genuinely unusual occurs versus when randomness simply manifests in an unexpected but statistically plausible way.

These findings provide a quantitative framework for understanding mid-tier seed performance in Women's March Madness. The methodology allows analysis at both the **aggregate level** (how many 8-12 seeds overall) and **individual team level** (which specific teams are most likely), making it valuable for bracket predictions, team evaluation, and understanding tournament dynamics.

---

# 6. References

- Bradley, R.A. and Terry, M.E. (1952). "Rank analysis of incomplete block designs: I. The method of paired comparisons." *Biometrika*, 39(3/4), 324-345.
- Turner, H. & Firth, D. (2020). *BradleyTerry2: Bradley-Terry Models in R*. R package version 1.1-2. https://CRAN.R-project.org/package=BradleyTerry2
- Hutchinson, G., Gilani, S., et al. (2023). *wehoop: Women's Basketball Data*. R package version 1.5.0. https://github.com/sportsdataverse/wehoop
- Nesbitt, S. (2024). *wncaahoopR: Women's NCAA Basketball Data Package*. https://github.com/snestler/wncaahoopR

---

# Appendix: Technical Details {.unnumbered}

## Software Environment

```{r session-info}
sessionInfo()
```

## Code Availability

All analysis code is available in the project repository organized as follows:

- **`scripts/00_helper_functions.R`**: Utility functions for file I/O, probability calculations
- **`scripts/01_data_collection_UPDATED.R`**: Data scraping, cleaning, and preparation
- **`scripts/02_bradley_terry_model.R`**: Bradley-Terry model fitting and team strength estimation
- **`scripts/03_seed_analysis.R`**: Analytical probability calculations by seed
- **`scripts/04_tournament_simulation.R`**: Monte Carlo tournament simulations (5,000 replications)
- **`scripts/05_visualization.R`**: Aggregate-level visualizations
- **`scripts/06_individual_team_probabilities.R`**: Individual team probability calculations
- **`scripts/07_individual_team_viz.R`**: Individual team visualizations

## Reproducibility

To reproduce this analysis:

```r
# Install required packages
install.packages(c("tidyverse", "here", "BradleyTerry2"))
devtools::install_github("sportsdataverse/wehoop")

# Run complete pipeline
source("run_all.R")

# Generate this report
rmarkdown::render("reports/final_report.Rmd")
```

## Data Processing Details

### Team Name Standardization

Team names were standardized across games to ensure consistency:

- Removed trailing/leading whitespace
- Standardized abbreviations (e.g., "St." vs. "State")
- Merged duplicate team entries

### Game Filtering

- **Included:** Regular season games only (September-February)
- **Excluded:** Exhibition games, conference tournaments, NCAA tournament games, games with missing score data

### Seed Assignment

For synthetic seeding:

1. Calculate win percentage for each team
2. Rank teams 1-64 by win%
3. Assign seeds 1-16 in each of 4 regions using serpentine draft order

---

*Report generated: `r Sys.Date()`*

*Course: STAT 479 - Sports Analytics, University of Wisconsin-Madison*
